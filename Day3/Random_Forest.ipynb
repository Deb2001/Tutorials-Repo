{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the potential split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data,random_subspace):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    column_indices = list(range(data.shape[1]-1))\n",
    "    \n",
    "    \n",
    "    if random_subspace and random_subspace < data.shape[1]:\n",
    "        column_indices = random.sample(population = column_indices,k = random_subspace)\n",
    "    \n",
    "    for column_index in  column_indices :\n",
    "            \n",
    "            values =data[:,column_index] \n",
    "            \n",
    "            if FEATURE_TYPES[column_index] == 'Continious':\n",
    "                \n",
    "                unique_values = np.unique(values)\n",
    "                potential_splits[column_index] = []\n",
    "                \n",
    "                for i in range(len(unique_values)-1):\n",
    "                    current_value = unique_values[i]\n",
    "                    next_value = unique_values[i+1]\n",
    "                    potential_split = (current_value+next_value)/2\n",
    "                \n",
    "                    potential_splits[column_index].append(potential_split)\n",
    "            \n",
    "            else:\n",
    "                potential_splits[column_index]=list(set(values))\n",
    "             \n",
    "            \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking type of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(data):\n",
    "    \n",
    "    feature_types = []\n",
    "    threshold = 15\n",
    "    \n",
    "    for column_index in range(data.shape[1]-1):\n",
    "        \n",
    "        unique_values = np.unique(data[:,column_index])\n",
    "            \n",
    "        if(len(unique_values)<=threshold)or isinstance(unique_values[0],str):\n",
    "            feature_types.append('Categorical')\n",
    "        else:\n",
    "            feature_types.append('Continious')\n",
    "            \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,split_column,split_value):\n",
    "    \n",
    "    values = data[:,split_column]\n",
    "    type_of_feature = FEATURE_TYPES[split_column] \n",
    "    \n",
    "    if type_of_feature == 'Continious':\n",
    "        data_above = data[values > split_value]\n",
    "        data_below = data[values <= split_value]\n",
    "    else:\n",
    "        data_below = data[values == split_value]\n",
    "        data_above = data[values != split_value]\n",
    "        \n",
    "    return data_below,data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data):\n",
    "    \n",
    "    label_column= data[:,-1]\n",
    "    _,counts = np.unique(label_column,return_counts=True)\n",
    "    \n",
    "    p=counts/counts.sum()\n",
    "    gini =1- np.dot(p,p)\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    \n",
    "    label_columns = data[:,-1]\n",
    "    _,counts = np.unique(label_columns,return_counts= True)\n",
    "    \n",
    "    p = counts/counts.sum()\n",
    "    entropy = sum(p*-np.log2(p))\n",
    "    \n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_metric(data_below,data_above,metric_function):\n",
    "    \n",
    "    n=len(data_above)+len(data_below)\n",
    "    p_data_below = len(data_below)/n\n",
    "    p_data_above = len(data_above)/n\n",
    "    \n",
    "    overall_metric = p_data_above*metric_function(data_above) + p_data_below*metric_function(data_below)\n",
    "    \n",
    "    return overall_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(data, potential_splits, metric_function = gini):\n",
    "    \n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            \n",
    "            data_below,data_above = split_data(data,split_column=column_index,split_value = value)\n",
    "            current_metric = overall_metric(data_above,data_below,metric_function)\n",
    "            \n",
    "            if first_iteration:\n",
    "                \n",
    "                best_metric = current_metric\n",
    "                first_iteration = False\n",
    "            \n",
    "            if current_metric <= best_metric :\n",
    "                \n",
    "                best_metric = current_metric\n",
    "                best_column =column_index\n",
    "                best_value = value\n",
    "                \n",
    "                \n",
    "    return best_column,best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  check_purity(data):\n",
    "    label_columns = data[:,-1]\n",
    "    \n",
    "    if len(np.unique(label_columns))==1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(data):\n",
    "    \n",
    "    label_columns = data[:,-1]\n",
    "    unique_labels,counts = np.unique(label_columns,return_counts =True)\n",
    "    \n",
    "    index = counts.argmax()\n",
    "    leaf = unique_labels[index]\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,split_ratio = 0.7,random_state=123):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.rand(len(df))<split_ratio\n",
    "    return df.iloc[indices,:],df.iloc[~indices,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data,n_bootstrap):\n",
    "    \n",
    "    indices =np.random.randint(low=0,high=len(data),size=n_bootstrap)\n",
    "    \n",
    "    return data[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(data,counter =0, max_depth =5,min_samples = 10,random_subspace=None,metric_function = gini):\n",
    "    \n",
    "    if counter == 0:\n",
    "    \n",
    "        global FEATURE_TYPES\n",
    "        FEATURE_TYPES = determine_type_of_feature(data)\n",
    "    \n",
    "    \n",
    "    if (check_purity(data)) or (counter == max_depth) or (len(data) < min_samples):\n",
    "        return create_leaf(data)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        potential_splits = get_potential_splits(data, random_subspace)\n",
    "        column_index,split_value = get_best_split(data, potential_splits, metric_function)\n",
    "        data_below,data_above = split_data(data, column_index, split_value)\n",
    "         \n",
    "        if len(data_below)==0 or len(data_above)==0 :\n",
    "            return create_leaf(data)\n",
    "        \n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[column_index]\n",
    "        #column_name = COLUMN_NAMES[column_index]\n",
    "        \n",
    "        if type_of_feature == 'Continious':\n",
    "            question = \"{} <= {}\".format(column_index,split_value)\n",
    "        else:\n",
    "            question =\"{} = {}\".format(column_index,split_value)\n",
    "        sub_tree={question:[]}\n",
    "        \n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, max_depth, min_samples,random_subspace  ,metric_function )\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, max_depth, min_samples,random_subspace  ,metric_function )\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree =yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "       \n",
    "        return sub_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifer(example,tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    column_index,comparison_operator,value =question.split()\n",
    "    column_index =int(column_index)\n",
    "    \n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[column_index] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        if str(example[column_index]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    if not isinstance(answer,dict):\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return decision_tree_classifer(example, residual_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_algorithm(train_data, n_trees,max_depth = 5,min_samples =10,random_state = 123, n_features = 3, n_bootstrap=50,metric_function =gini):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    forest = []\n",
    "    for i in range(n_trees):\n",
    "        \n",
    "        bootstrapped_data = bootstrap(train_data,n_bootstrap)\n",
    "        tree = decision_tree_algorithm(data = bootstrapped_data, counter=0, random_subspace = n_features, max_depth = max_depth,metric_function=metric_function)\n",
    "        forest.append(tree)\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_tree_classifier(example,forest):\n",
    "    \n",
    "    results =[]\n",
    "    for index in range(len(forest)):\n",
    "        \n",
    "        result = decision_tree_classifer(example, forest[index] )\n",
    "        results.append(result)\n",
    "        \n",
    "    mode = max(set(results),key=results.count)\n",
    "    return mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(test_df,forest):\n",
    "    \n",
    "    Predictions = test_df.apply(func = random_tree_classifier, axis = 1, raw=True,args=(forest,))\n",
    "    \n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(labels,predictions):\n",
    "        \n",
    " \n",
    "    accuracy = np.array(labels == predictions).mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing  the SKLearn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['variance', 'skewness', 'curtosis', 'entropy', 'class']\n",
    "data = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
    "banknote = pd.read_csv(data, names= columns)\n",
    "banknote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(967, 5)\n",
      "(405, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df ,test_df= train_test_split(banknote)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 400 ms, sys: 0 ns, total: 400 ms\n",
      "Wall time: 397 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest=random_forest_algorithm(train_df.values,n_trees = 5,n_features=2,n_bootstrap=100,random_state =120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classify_data(test_df.iloc[:,:-1],forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 94.32098765432099\n"
     ]
    }
   ],
   "source": [
    "labels = test_df.iloc[:,-1]\n",
    "\n",
    "print(\"Accuracy is : {}\".format(calculate_accuracy(predictions,labels)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.values[:,:-1]\n",
    "y_train = train_df.values[:,-1]\n",
    "X_test = test_df.values[:,:-1]\n",
    "y_test = test_df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 314 ms, sys: 11.8 ms, total: 326 ms\n",
      "Wall time: 327 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=3, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_entropy = RandomForestClassifier( criterion = \"entropy\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_entropy.predict(X_test)\n",
    "\n",
    "print (\"Accuracy is \", accuracy_score(y_test , y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
