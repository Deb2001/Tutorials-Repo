{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the potential split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data,random_subspace):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    column_indices = list(range(data.shape[1]-1))\n",
    "    \n",
    "    \n",
    "    if random_subspace and random_subspace < data.shape[1]:\n",
    "        column_indices = random.sample(population = column_indices,k = random_subspace)\n",
    "    \n",
    "    for column_index in  column_indices :\n",
    "            \n",
    "            values =data[:,column_index] \n",
    "            \n",
    "            if FEATURE_TYPES[column_index] == 'Continious':\n",
    "                \n",
    "                unique_values = np.unique(values)\n",
    "                potential_splits[column_index] = []\n",
    "                \n",
    "                for i in range(len(unique_values)-1):\n",
    "                    current_value = unique_values[i]\n",
    "                    next_value = unique_values[i+1]\n",
    "                    potential_split = (current_value+next_value)/2\n",
    "                \n",
    "                    potential_splits[column_index].append(potential_split)\n",
    "            \n",
    "            else:\n",
    "                potential_splits[column_index]=list(set(values))\n",
    "             \n",
    "            \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking type of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    threshold = 15\n",
    "    \n",
    "    for feature_names in list(df.columns)[:-1]:\n",
    "        \n",
    "        unique_values =df[feature_names].unique()\n",
    "            \n",
    "        if(len(unique_values)<=threshold)or isinstance(unique_values[0],str):\n",
    "            feature_types.append('Categorical')\n",
    "        else:\n",
    "            feature_types.append('Continious')\n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,split_column,split_value):\n",
    "    \n",
    "    values = data[:,split_column]\n",
    "    type_of_feature = FEATURE_TYPES[split_column] \n",
    "    \n",
    "    if type_of_feature == 'Continious':\n",
    "        data_above = data[values > split_value]\n",
    "        data_below = data[values <= split_value]\n",
    "    else:\n",
    "        data_below = data[values == split_value]\n",
    "        data_above = data[values != split_value]\n",
    "    return data_below,data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data):\n",
    "    \n",
    "    label_column= data[:,-1]\n",
    "    _,counts = np.unique(label_column,return_counts=True)\n",
    "    \n",
    "    p=counts/counts.sum()\n",
    "    gini =1- np.dot(p,p)\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    \n",
    "    label_columns = data[:,-1]\n",
    "    _,counts = np.unique(label_columns,return_counts= True)\n",
    "    \n",
    "    p = counts/counts.sum()\n",
    "    entropy = sum(p*-np.log2(p))\n",
    "    \n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_metric(data_below,data_above,metric_function):\n",
    "    \n",
    "    n=len(data_above)+len(data_below)\n",
    "    p_data_below = len(data_below)/n\n",
    "    p_data_above = len(data_above)/n\n",
    "    \n",
    "    overall_metric = p_data_above*metric_function(data_above) + p_data_below*metric_function(data_below)\n",
    "    \n",
    "    return overall_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(data,potential_splits,metric_function = gini):\n",
    "    \n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            \n",
    "            data_below,data_above = split_data(data,split_column=column_index,split_value = value)\n",
    "            current_metric = overall_metric(data_above,data_below,metric_function)\n",
    "            \n",
    "            if first_iteration:\n",
    "                \n",
    "                best_metric = current_metric\n",
    "                first_iteration = False\n",
    "            \n",
    "            if current_metric <= best_metric :\n",
    "                \n",
    "                best_metric = current_metric\n",
    "                best_column =column_index\n",
    "                best_value = value\n",
    "                \n",
    "                \n",
    "    return best_column,best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  check_purity(data):\n",
    "    label_columns = data[:,-1]\n",
    "    \n",
    "    if len(np.unique(label_columns))==1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(data):\n",
    "    \n",
    "    label_columns = data[:,-1]\n",
    "    unique_labels,counts = np.unique(label_columns,return_counts =True)\n",
    "    \n",
    "    index = counts.argmax()\n",
    "    leaf = unique_labels[index]\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,split_ratio = 0.7,random_state=123):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.rand(len(data))<split_ratio\n",
    "    \n",
    "    return data[indices],data[~indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(df,n_bootstrap,random_state = 1729):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    indices =np.random.randint(low=0,high=len(df),size=n_bootstrap)\n",
    "    \n",
    "    return df.iloc[indices,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df,counter =0, max_depth =5,min_samples = 10,random_subspace=None):\n",
    "    \n",
    "    if counter == 0:\n",
    "    \n",
    "        global COLUMN_NAMES,FEATURE_TYPES\n",
    "        COLUMN_NAMES = list(df.columns)\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data =df.values\n",
    "    \n",
    "    else:\n",
    "        data =df\n",
    "    \n",
    "    if (check_purity(data)) or (counter == max_depth) or (len(data) < min_samples):\n",
    "        return create_leaf(data)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        counter += 1\n",
    "        potential_splits = get_potential_splits(data,random_subspace)\n",
    "        column_index,split_value = get_best_split(data,potential_splits)\n",
    "        data_below,data_above = split_data(data, column_index, split_value)\n",
    "         \n",
    "        if len(data_below)==0 or len(data_above)==0 :\n",
    "            return create_leaf(data)\n",
    "        \n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[column_index]\n",
    "        if type_of_feature == 'Continious':\n",
    "            question = \"{} <= {}\".format(column_index,split_value)\n",
    "        else:\n",
    "            question =\"{} = {}\".format(column_index,split_value)\n",
    "        sub_tree={question:[]}\n",
    "        \n",
    "        yes_answer = decision_tree_algorithm(data_below,counter,random_subspace)\n",
    "        no_answer = decision_tree_algorithm(data_above,counter,random_subspace)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree =yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "       \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifer(example,tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    column_index,comparison_operator,value =question.split()\n",
    "    column_index =int(column_index)\n",
    "    \n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[column_index] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        if str(example[column_index]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return decision_tree_classifer(example, residual_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_algorithm(train_df,n_trees,n_bootstrap,n_features,max_depth=5):\n",
    "    \n",
    "    forest = []\n",
    "    for i in range(n_trees):\n",
    "        \n",
    "        df_bootstrapped = bootstrap(train_df,n_bootstrap)\n",
    "        tree = decision_tree_algorithm(df = df_bootstrapped,random_subspace = n_features, max_depth = max_depth)\n",
    "        forest.append(tree)\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_tree_classifier(example,forest):\n",
    "    \n",
    "    results =[]\n",
    "    for index in range(len(forest)):\n",
    "        \n",
    "        result = decision_tree_classifer(example, forest[index] )\n",
    "        results.append(result)\n",
    "        \n",
    "    mode = max(set(results),key=results.count)\n",
    "    return mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(test_df,forest):\n",
    "    \n",
    "    Predictions = test_df.apply(func = random_tree_classifier, axis = 1, raw=True,args=(forest,))\n",
    "    \n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Accuracy(labels,predictions):\n",
    "        \n",
    " \n",
    "    accuracy = np.array(labels == predictions).mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
